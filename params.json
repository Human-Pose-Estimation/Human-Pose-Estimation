{
  "name": "Human-pose-estimation",
  "tagline": "",
  "body": "\r\n# Dataset Description  \r\n   Our kinect2 human gesture dataset(K2HGD) is composed about 100K depth images captured by kinect2. We transformed the depth value of the image to 0~255.K2HGD contains many different posees with different distances in many different scenes, including many challenging scenes and some unusual poses and occluded-poses.We used 60K for traning and 40K for testing in our paper _**Human Pose Estimation from Depth Data via Inference Embedded Multitask Learning**_ \r\n \r\n   The K2HGD dataset contains many human activies in usual life and some unusual posees in very challenging scenes. We captured theses depth images using kinect2 because kinect2 has a better depth image sensor compared to other similar devices such as kinect1 or xtion.When using kinect2 depth images for our model, we find that images captured by kinect2 is better for both accuracy and robustness. We use people to examine these depth images and for those  accuracy, we leave it as the groundtruth. for those not accurate, we only change the position of non-accurate part and leave others as kinect2 detected them. We used our own fast and  convenient java tools to adjust these joint positions, which can be very accurate with the location showing in each image.  \r\n\r\n#Dataset Details\r\n  The dataset contains depth images captured by kinect2 with different people(boys and girls,about 30), different height,different distances and different challenging sceness(from simple scenes with only white wall to very challenging scenes which include many normal objects such as chairs). The dataset is aimed at detecting human gestures, so many depthimages are human usual life gestures.\r\nBesides, We captured many unusual gestures and images with self-occlusion for the puspose of getting better detecting accuracy and generalization. the gestures our dataset contains has the following class(far more than that, We only show some standard of them because many gesture is combination of many gestures or you can't say clearly what class the belong):  \r\n> 1.Calling phone  \r\n> 2.Drinking water  \r\n> 3.Tai Chi  \r\n> 4.Walk around  \r\n> 5.Give a strecth  \r\n> 6.Pickup something  \r\n> 7.Driving car  \r\n> 8.Wipe the glass  \r\n> 9.Playing Basketball(Jump)  \r\n> 10.Put on/Take off spectacles  \r\n> 11.setting-up exercises to music  \r\n> 11.Other normal upper body movement  \r\n> 12.unusual poses   \r\n> 13.Poses with self-occlusion   \r\n\r\nThe following is some examples of our dataset:\r\n![](trainimagesdemo/00000011.png)\r\n![](trainimagesdemo/00000871.png)\r\n![](trainimagesdemo/00002550.png)\r\n![](trainimagesdemo/00002793.png)\r\n![](trainimagesdemo/00002999.png)\r\n![](trainimagesdemo/00003345.png)\r\n![](trainimagesdemo/00003368.png)\r\n![](trainimagesdemo/00003972.png)\r\n![](trainimagesdemo/00004056.png)\r\n![](trainimagesdemo/00004244.png)\r\n![](trainimagesdemo/00004430.png)\r\n![](trainimagesdemo/00004826.png)\r\n![](trainimagesdemo/00005104.png)\r\n![](trainimagesdemo/00006454.png)\r\n![](trainimagesdemo/00007389.png)\r\n![](trainimagesdemo/00007918.png)\r\n![](trainimagesdemo/00010250.png)\r\n![](trainimagesdemo/00010352.png)\r\n![](trainimagesdemo/00011249.png)\r\n![](trainimagesdemo/00011481.png)\r\n![](trainimagesdemo/00013244.png)\r\n![](trainimagesdemo/00013311.png)\r\n![](trainimagesdemo/00013358.png)\r\n![](trainimagesdemo/00014174.png)\r\n![](trainimagesdemo/00015344.png)\r\n![](trainimagesdemo/00021926.png)\r\n![](trainimagesdemo/00026835.png)\r\n![](trainimagesdemo/00042249.png)\r\n![](trainimagesdemo/00061083.png)\r\n![](trainimagesdemo/00061775.png)\r\n![](trainimagesdemo/00061784.png)\r\n![](trainimagesdemo/00062639.png)\r\n![](trainimagesdemo/00064502.png)\r\n![](trainimagesdemo/00066345.png)\r\n![](trainimagesdemo/00067293.png)\r\n![](trainimagesdemo/00067785.png)\r\n![](trainimagesdemo/00073329.png)\r\n![](trainimagesdemo/00086992.png)\r\n![](trainimagesdemo/00090665.png)\r\n![](trainimagesdemo/00090910.png)\r\n![](trainimagesdemo/00094126.png)  \r\n\r\nfor more details of our dataset, you can download our dataset.We split the dataset to 2 parts: the first one is mainly normal gestures and some unusual and self-occlusion, and the second includes many unusual poses and self-occlusion. When training and tesing using our dataset, you should use both the first and the second to get better results.  \r\n\r\nThe first part dataset:\r\n[http://pan.baidu.com/s/1mitRWjI]  \r\n\r\nThe second part dataset:\r\n[http://pan.baidu.com/s/1bpeBofl]",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}