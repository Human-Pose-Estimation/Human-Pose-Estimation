{
  "name": "Human-pose-estimation",
  "tagline": "",
  "body": "\r\n# Dataset Description  \r\n***\r\nour kinect2 human gesture dataset(K2HGD) is composed about 100K depth images captured by kinect2. We transformed the depth value of the image to 0~255.K2 contains many different posees with different distances in many different scenes, including many challenging scenes and some unusual poses and occluded-poses.We used 60K for traning and 40K for testing in our paper_**Human Pose Estimation from Depth Data via Inference Embedded Multitask Learning**_\r\n\r\n#Dataset Details\r\n***\r\nthe K2HGD dataset contains many human activies in usual life and some unusual pose in very challenging scenes. We captured theses depth images using kinect2 because kinect2 has a better depth image sensor compared to other similar devices such as kinect1 or xtion.When using dept images for our model, we find that images captured by kinect2 is better for both accuracy and robustness. We use people to examine these depth images and for those  accuracy, we leave it as the groundtruth. for those not accurate, we only change the position of non-accurate part and leave others as kinect2 detected them. We used our own fast and  convenient java tools to adjust these joint positions, which can be very accurate with the location showing in each image.  \r\n[http://pan.baidu.com/s/1miaVe4o](http://pan.baidu.com/s/1miaVe4o)",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}